import csvimport openpyxl as pximport xlrdimport reimport nltkimport numpy as npimport pandas as pdimport timeitfrom nltk.stem import PorterStemmerfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.ensemble import VotingClassifierfrom sklearn import linear_modelfrom sklearn import svmfrom sklearn.neural_network import MLPClassifierfrom sklearn.utils import shufflefrom sklearn import metricsfrom sklearn.naive_bayes import BernoulliNBfrom sklearn.model_selection import train_test_splitfrom sklearn import metricsfrom nltk.stem.snowball import SnowballStemmer# from sklearn import ensemble# from sklearn import datasets# from sklearn.utils import shufflefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import AdaBoostClassifier# from sklearn.metrics import mean_squared_errorfrom sklearn.naive_bayes import GaussianNBfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.ensemble import GradientBoostingClassifierdef preprocess(file_name, sheetname, csvoutput):    data=np.array(data2)    data_labels = data[:, 1]    data_tweets = data[:, 0]    #-------------------PREPROCESS TEST DATA    data2 = [];    #Excelsheet = px.load_workbook('testing-Obama-Romney-tweets-3labels.xlsx')    Excelsheet = px.load_workbook('testupdated.xlsx')    sheet = Excelsheet.get_sheet_by_name(name=sheetname)    csv_file = open('testd.csv', 'w', newline='')    wr = csv.writer(csv_file, delimiter=',', quoting=csv.QUOTE_ALL)    counter=0    data2=[];    ########PREPROCESS TEST DATA FINISH    data_test=np.array(data2)    data_labels_test = data_test[:, 1]    data_tweets_test = data_test[:, 0]    accuracy_all_iter=[]    precision_all=[]    recall_all= []    f1_score_all=[]    if 1==1:        np.random.shuffle(data)        data_labels = data[:, 1]        data_tweets = data[:, 0]        X_train=data_tweets;        y_train=data_labels        X_test = data_tweets_test;        y_test=data_labels_test        #print('----Iteration '+str(1)+'----')        tfidf_v = TfidfVectorizer(lowercase=True)        tfidf_train = tfidf_v.fit_transform(X_train)        tfidf_test = tfidf_v.transform(X_test)        # ::::::::CLASSIFIERS::::::::::        # ---K Nearest Neibour        knn_clf = KNeighborsClassifier(n_neighbors=1)        # ---NEURAL NETWORKS        nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes = (50, 20), random_state = 1)        # ---NAIVE BAYES CLASSIFIER        naiveb_clf = MultinomialNB(alpha=1.5)        clf_gbc =  AdaBoostClassifier(MultinomialNB(alpha=1),algorithm="SAMME.R",n_estimators=500)        #GN=GaussianNB()        # ---REGRESSION, LOGISTIC        lr_clf = linear_model.LogisticRegression(C=1e5)        # ---Stochastic Gradient Descent classifier        gradient_clf = linear_model.SGDClassifier(loss='log')        # ---SUPPORT VECTOR MACHINE        supportvector_clf = svm.SVC(kernel='rbf', C=1.5, gamma=1.2)        # Extreme Gradient Boosting        # params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,'learning_rate': 0.01, 'loss': 'ls'}        # GB_clf = ensemble.GradientBoostingRegressor(**params)        # Combining Classifiers        # combine_clf = VotingClassifier(estimators=[('Naivebayes', naiveb_clf), ('SupportVector', supportvector_clf), ('StochGradient', gradient_clf)], voting='hard')        combine_clf = VotingClassifier(estimators=[('SVM', supportvector_clf)], voting='hard')        combine_clf = supportvector_clf.fit(tfidf_train, y_train)        combination_p = combine_clf.predict(tfidf_test)        # Accuracy of the aggregate classifiers        combination_accuracy = metrics.accuracy_score(y_test, combination_p)        print ('Accuracy:', combination_accuracy)        labels_order = ['-1', '1']        accuracy_all_iter.append(combination_accuracy)        precision = metrics.precision_score(y_test, combination_p, average=None,labels=labels_order)        precision_all.append(precision);        recall = metrics.recall_score(y_test, combination_p, average=None,labels=labels_order)        recall_all.append(recall);        f1 = metrics.f1_score(y_test, combination_p, average=None,labels=labels_order)        f1_score_all.append(f1);        '''        confusion_metrics = metrics.confusion_matrix(y_test, combination_p,labels=labels_order)        print('Precision:', precision)        print('Recall:', recall)        print('F1 Score:', f1)        print ('Confusion Matrix:\n',confusion_metrics)        '''    # print ('K-FOLD Average accuracy of', str(sheet2),' :',np.mean(np.array(accuracy_all_iter)))    elapsed = timeit.default_timer() - start_time    precision = []    precision = np.mean(np.array(precision_all), axis=0)    recall = []    recall = np.mean(np.array(recall_all), axis=0)    fscore = []    fscore = np.mean(np.array(f1_score_all), axis=0)    print('-------POSITIVE CLASS-------')    print('Precision for', str(sheet1), ' :', precision[0])    print('Recall for', str(sheet1), ' :', recall[0])    print('F1 for', str(sheet1), ' :', fscore[0])    print('')    print('-------NEGATIVE CLASS-------')    print('Precision for', str(sheet1), ' :', precision[1])    print('Recall for', str(sheet1), ' :', recall[1])    print('F1 for', str(sheet1), ' :', fscore[1])    print('')    elapsed = timeit.default_timer() - start_time    print("The Total run time of the script was ", elapsed, " seconds.")# -----------RUN SETTINGSfile_name='training-Obama-Romney-tweets.xlsx'sheet1 = 'Obama'#sheet1 = 'Romney'# preprocess(file_name, sheet2, str(sheet2)+'.csv')   # romneypreprocess(file_name, sheet1, str(sheet1)+'.csv')   # Obamma#-----------RUN SETTINGS